{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def stretch_channel(channel):\n",
    "    min_val = np.min(channel)\n",
    "    max_val = np.max(channel)\n",
    "    stretched_channel = ((channel - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "    return stretched_channel\n",
    "\n",
    "def stretch_image(image):\n",
    "    b, g, r = cv2.split(image)\n",
    "    b_stretched = stretch_channel(b)\n",
    "    g_stretched = stretch_channel(g)\n",
    "    r_stretched = stretch_channel(r)\n",
    "    stretched_image = cv2.merge((b_stretched, g_stretched, r_stretched))\n",
    "    return stretched_image\n",
    "\n",
    "def enhance_image(image):\n",
    "    # Apply histogram equalization to enhance contrast\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge([l_eq, a, b])\n",
    "    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Apply color correction for underwater video\n",
    "    corrected_image = gray_world(enhanced_image)\n",
    "    \n",
    "    return corrected_image\n",
    "\n",
    "def gray_world(image):\n",
    "    # Apply gray world assumption for color correction\n",
    "    avg_b = np.mean(image[:, :, 0])\n",
    "    avg_g = np.mean(image[:, :, 1])\n",
    "    avg_r = np.mean(image[:, :, 2])\n",
    "    \n",
    "    avg_gray = (avg_b + avg_g + avg_r) / 3\n",
    "    \n",
    "    scale_r = avg_gray / avg_r\n",
    "    scale_g = avg_gray / avg_g\n",
    "    scale_b = avg_gray / avg_b\n",
    "    \n",
    "    balanced_image = np.zeros_like(image, dtype=np.float32)\n",
    "    balanced_image[:, :, 0] = image[:, :, 0] * scale_b\n",
    "    balanced_image[:, :, 1] = image[:, :, 1] * scale_g\n",
    "    balanced_image[:, :, 2] = image[:, :, 2] * scale_r\n",
    "    \n",
    "    return np.clip(balanced_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Load video\n",
    "video_path = \"C:/Users/manda/Downloads/FOGGY Underwater video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Couldn't open the video.\")\n",
    "    exit()\n",
    "\n",
    "# Process each frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Apply filters\n",
    "    stretched_frame = stretch_image(frame)\n",
    "    enhanced_frame = enhance_image(stretched_frame)\n",
    "    \n",
    "    # Display the processed frame\n",
    "    cv2.imshow('Processed Frame', enhanced_frame)\n",
    "    \n",
    "    # Check for 'q' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture\n",
    "cap.release()\n",
    "\n",
    "# Destroy any OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
